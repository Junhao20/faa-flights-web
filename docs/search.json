[
  {
    "objectID": "maximal-early-departure.html",
    "href": "maximal-early-departure.html",
    "title": "How is the overall on-time departure performance in the US? AND WHY?",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nq1 = pd.read_csv(\"data/q1_maxdelay_air.csv\")\nq2 = pd.read_csv(\"data/q2_max_early_departure_minutes.csv\")\n\n# clean the data as necessary\nq1 = q1[q1[\"Reporting_Airline\"] != \"Reporting_Airline\"].copy()\nq1[\"max_delay\"] = q1[\"max_delay\"].astype(int)\nq2 = q2[q2[\"Reporting_Airline\"] != \"Reporting_Airline\"].copy()\nq2.rename(columns={\"max_early_departure_minutes\": \"max_early\"}, inplace=True)\nq2[\"max_early\"] = q2[\"max_early\"].astype(int)\n\nmerged = pd.merge(q1, q2, on=\"Reporting_Airline\", how=\"inner\")\nmerged = merged.sort_values(\"max_delay\", ascending=True)\n\nairlines   = merged[\"Reporting_Airline\"]\nmax_delay  = merged[\"max_delay\"]\nmax_early  = merged[\"max_early\"]\n\nearly_neg = -max_early\nmax_val = max(max_delay.max(), max_early.max())\nxlim = max_val * 1.1\nplt.rcParams.update({\n    \"figure.figsize\": (7, 5),\n    \"font.size\": 11,\n    \"axes.grid\": True,\n    \"grid.linestyle\": \"--\",\n    \"grid.alpha\": 0.3,\n    \"figure.dpi\": 120,\n})\nfig, ax = plt.subplots()\nax.barh(airlines, early_neg,  color=\"#1f77b4\", label=\"Maximum early departure\")\nax.barh(airlines, max_delay, color=\"#d62728\", label=\"Maximum late departure\")\nax.axvline(0, color=\"black\", linewidth=1)\nax.set_xlim(-xlim, xlim)\nax.set_xlabel(\"Extreme departure minutes (early to the left, late to the right)\")\nax.set_ylabel(\"Airline\")\nax.set_title(\"Airline extremes: earliest and latest departures\")\nxticks = ax.get_xticks()\nax.set_xticklabels([f\"{abs(int(x))}\" for x in xticks])\nfor y, e, d in zip(airlines, early_neg, max_delay):\n    # early (left)\n    ax.text(e - xlim*0.02, y, f\"{abs(e):.0f}\", va=\"center\", ha=\"right\", fontsize=8)\n    # late (right)\n    ax.text(d + xlim*0.02, y, f\"{d:.0f}\", va=\"center\", ha=\"left\", fontsize=8)\n\nax.legend(loc=\"lower right\", frameon=False)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nFrom the chart above, it is not hard to see that the early departure is far less than the delays. So far, the Alaska airlines has the best record for early departures.\nFrom this plot it feels like the story is not just about which airline has the single worst delay, but about how extreme and rare these events are. Some carriers show very long late departures, over three thousand minutes, which is more than two days, so that probably comes from very unusual events like major storms, mechanical problems, or schedule changes. A next step could compare these extremes to the typical delay for each airline, using averages or medians, to see whether a big spike is just one bad day or part of a larger pattern. It would also be interesting to check how many flights for each airline leave very early or very late, maybe by counting the share of departures that are more than one hour off the schedule. Another idea is to break the same analysis by airport or by region, to see whether some hubs create these extreme values more often than others. Looking at those extra views would make the chart less about one dramatic number and more about how each airline usually treats passengers."
  },
  {
    "objectID": "maximal-delays.html",
    "href": "maximal-delays.html",
    "title": "Why Your Flight Was Late: A Deep Dive Into U.S. Airline Delays",
    "section": "",
    "text": "Choose your airlines before travel\nChoosing airlines is crutial for your travel. Some airlines simply have more delays due to its poor service. For example, if an airline does not purchase for the gate for boarding, the delay is more likely to occur.\nConsequently, in this visualization, we are going to tell you, during the April 2024, which airline has the most delay overall.\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.rcParams.update({\n    \"figure.figsize\": (7, 4),\n    \"font.size\": 11,\n    \"axes.labelsize\": 12,\n    \"axes.titlesize\": 13,\n    \"xtick.labelsize\": 10,\n    \"ytick.labelsize\": 10,\n    \"legend.fontsize\": 10,\n    \"axes.grid\": True,\n    \"grid.linestyle\": \"--\",\n    \"grid.alpha\": 0.4,\n    \"figure.dpi\": 120, # download friendly\n})\n\n\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\nq1 = pd.read_csv(\"data/q1_maxdelay_air.csv\")\nq1 = q1[q1[\"Reporting_Airline\"] != \"Reporting_Airline\"].copy()\nq1[\"max_delay\"] = q1[\"max_delay\"].astype(int)\n\nq1 = q1.sort_values(\"max_delay\", ascending=True)\n\nfig, ax = plt.subplots()\nax.barh(q1[\"Reporting_Airline\"], q1[\"max_delay\"])\nax.set_xlabel(\"Maximum departure delay (minutes)\")\nax.set_ylabel(\"Airline\")\nax.set_title(\"Maximum observed departure delay by airline\")\n\nfor i, (delay) in enumerate(q1[\"max_delay\"]):\n    ax.text(delay + 15, i, f\"{delay}\", va=\"center\", fontsize=9)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nAirline (full name)\nCountry\nExample high-traffic / flagship route*\n\n\n\n\nAA\nAmerican Airlines\nUSA\nDallas/Fort Worth (DFW) – Los Angeles (LAX)\n\n\nB6\nJetBlue Airways\nUSA\nMiami (MIA) – New York–JFK (JFK)\n\n\nOH\nPSA Airlines\nUSA\nCleveland (CLE) – Washington Reagan (DCA)**\n\n\nMQ\nEnvoy Air\nUSA\nRegional feeder routes for American (AAdvantage hubs such as DFW, ORD, MIA)\n\n\nOO\nSkyWest Airlines\nUSA\nRegional feeder network linking small cities to hubs (e.g., DEN, SLC, ORD, LAX)\n\n\nG4\nAllegiant Air\nUSA\nAllentown (ABE) – Orlando (MCO)\n\n\nYX\nRepublic Airways\nUSA\nRegional feeder for American / Delta / United (Midwest & East Coast hubs)\n\n\nF9\nFrontier Airlines\nUSA\nDenver (DEN) – Las Vegas (LAS)\n\n\nUA\nUnited Airlines\nUSA\nNewark (EWR) – Orlando (MCO)\n\n\nDL\nDelta Air Lines\nUSA\nAtlanta (ATL) – Orlando (MCO)\n\n\nHA\nHawaiian Airlines\nUSA\nHonolulu (HNL) – Kahului, Maui (OGG)\n\n\n9E\nEndeavor Air\nUSA\nDelta Connection feeder network (ATL, DTW, MSP, JFK, LGA, RDU hubs\n\n\n\nFrom the chart and table above, we are able to see that the American Airline, Jetblue Airways, and PSA Airlines has the worst performance in terms of on-time departure. (Additional information, PSA airlines is also an American Airlines firm, which serves as a regional express.)\nCompare with American Airlines and PSA Airlines, the JetBlue’s performance is more understandable, since they are offering the ticket with less price. However, if you are looking for both price and on-time rate, I would not recommend you to choose American Airlines.\n\nWhich airlines would I choose?\nBased on this set of airlines, there are a few that I would personally feel most comfortable choosing as a traveler:\n\nDelta Air Lines (DL) – One of the largest U.S. network carriers, with a dense hub in Atlanta (ATL) and strong coverage across the U.S. and internationally. Delta is often seen as a reliable “default” choice for many domestic and international routes.\nUnited Airlines (UA) - One of the largest arlines in the US as well. The major difference between UA and DL is that UA is more affordable compared with the delta airlines. For the travellers who is under 23 years old, they are eligible for a discounted travel. Moreover, its international flights, for example, New York to London, Washington to Hong Kong, are the most affordable compare with other airlines, and without too much transfer.\n\nOf course, delay performance depends on many factors (weather, congestion, airport, time of day), so this list is not a strict ranking. It is simply a short narrative about a few airlines from the table that a typical traveler might be inclined to choose, given their networks and general reputation."
  },
  {
    "objectID": "flight-volume-by-day-of-week.html",
    "href": "flight-volume-by-day-of-week.html",
    "title": "Which day to fly in April?",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# read\nq3 = pd.read_csv(\"data/q3.csv\")\n\n# drop rows with missing day_name or with the header accidentally repeated\nq3 = q3[q3[\"day_name\"].notna()].copy()\nq3 = q3[q3[\"day_name\"] != \"day_name\"].copy()\n\n# make sure numeric columns are numeric\nq3[\"num_flights\"] = pd.to_numeric(q3[\"num_flights\"], errors=\"coerce\")\nq3[\"day_rank\"]   = pd.to_numeric(q3[\"day_rank\"], errors=\"coerce\")\n\n# drop any rows that still have NaNs in key columns\nq3 = q3.dropna(subset=[\"num_flights\", \"day_rank\"])\n\n# sort by rank (1 = busiest)\nq3_sorted = q3.sort_values(\"day_rank\")\n\n# ----- publication-style bar chart -----\nplt.rcParams.update({\n    \"figure.figsize\": (7, 4),\n    \"font.size\": 11,\n    \"axes.grid\": True,\n    \"grid.linestyle\": \"--\",\n    \"grid.alpha\": 0.3,\n    \"figure.dpi\": 120,\n})\n\nfig, ax = plt.subplots()\n\nx = range(len(q3_sorted))\nax.bar(x, q3_sorted[\"num_flights\"], width=0.6)\n\nax.set_xticks(x)\nax.set_xticklabels(q3_sorted[\"day_name\"])\n\nax.set_xlabel(\"Day of week\")\nax.set_ylabel(\"Number of flights\")\nax.set_title(\"Flight volume by day of week\")\n\n# annotate rank above each bar\ny_offset = q3_sorted[\"num_flights\"].max() * 0.01\nfor i, (_, row) in enumerate(q3_sorted.iterrows()):\n    ax.text(\n        i,\n        row[\"num_flights\"] + y_offset,\n        f\"Rank {int(row['day_rank'])}\",\n        ha=\"center\",\n        va=\"bottom\",\n        fontsize=9,\n    )\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nThis chart indicating that all flights in April and counts how many departed on each day of the week. Monday has the highest volume of flights, followed by Tuesday, so the start of the work week is clearly the busiest time in the air. That matches what we expect from business travel, since many people fly out on Monday or Tuesday for meetings. The quietest day is Saturday, with Wednesday also on the lower side, which suggests that mid- and late-week trips are less common than early-week travel. If the goal is to avoid crowds and have a better chance at less busy airports, Saturday (rank 7) or Wednesday (rank 6) look like the best choices in April. If the goal is to have the most possible flight options, Monday and Tuesday remain the strongest days, even though they come with more traffic."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Why Your Flight Was Late? A comprehensive guide to prevent delays for your flights!",
    "section": "",
    "text": "Delays is always been a painful thing to experience for all of the travellers in the world. Recently, increasing numbers of delays in airlines in the US impact millions of people’s travel plan. Of course, including mine…\nSo what actually causing the delays?\n\nWeather\nThunderstorms, snow, low visibility, and strong winds can slow down takeoffs and landings or close runways completely. Even if the weather is fine at your airport, bad conditions at a previous stop can still delay your flight.\nAir traffic congestion\nBusy hubs like ATL, ORD, or JFK handle thousands of flights per day. When the airspace or runways are crowded, air traffic control may hold departures or arrivals to keep the system safe, which creates a chain of delays.\nLate arriving aircraft\nMany flights reuse the same plane throughout the day. If an earlier leg arrives late, the next departure often cannot leave on time, even if everything else is ready.\nAirline operations and scheduling\nTurnaround times that are too tight, crew scheduling conflicts, or last-minute aircraft swaps can push flights behind schedule.\nCrew availability and duty limits\nPilots and flight attendants must follow strict duty-time rules. If a crew times out because of earlier delays, the airline has to find a replacement crew before the flight can depart.\nMaintenance and safety checks\nMechanical issues, unexpected inspections, or minor repairs can keep an aircraft at the gate longer than planned. These delays are frustrating, but they are usually done for safety reasons.\nSecurity and airport processes\nSecurity incidents, long lines at checkpoints, or problems with baggage handling and boarding can also add extra minutes to departure times.\n\nTogether, these factors create a complex system where a single disruption can ripple through many flights and airports.\n\n\n\nIn this project, I use FAA flight data to explore flight delays from several angles:\n\nMaximal delays – Which flights experienced the longest delays, and when did they occur?\n\nMaximal early departures – Are there flights that regularly leave much earlier than scheduled?\n\nMoving-average flights – How does flight activity change over time when we smooth out daily noise?\n\nFlight cancellations – Where and when are cancellations most common?\n\nWorst airports – Which airports tend to have the worst delay or cancellation performance?\n\nEach page of this site focuses on one of these questions and uses tables and visualizations to turn raw FAA data into interpretable insights about how the U.S. air travel system behaves."
  },
  {
    "objectID": "index.html#what-this-website-shows",
    "href": "index.html#what-this-website-shows",
    "title": "Why Your Flight Was Late? A comprehensive guide to prevent delays for your flights!",
    "section": "",
    "text": "In this project, I use FAA flight data to explore flight delays from several angles:\n\nMaximal delays – Which flights experienced the longest delays, and when did they occur?\n\nMaximal early departures – Are there flights that regularly leave much earlier than scheduled?\n\nMoving-average flights – How does flight activity change over time when we smooth out daily noise?\n\nFlight cancellations – Where and when are cancellations most common?\n\nWorst airports – Which airports tend to have the worst delay or cancellation performance?\n\nEach page of this site focuses on one of these questions and uses tables and visualizations to turn raw FAA data into interpretable insights about how the U.S. air travel system behaves."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About the author",
    "section": "",
    "text": "Hi everyone, my name is Hermann Junhao Fan. I am currently a second-year graduate student at Georgetown University, majoring in Data Science and Analytics.\n\nAcademic Experience\n\nGeorgetown University (M.S.), Data Science and Analytics Coursework in time series, machine learning, data visualization, and large-scale data processing.\nTsinghua University, School of Electronic Engineering (Pre-Doc), visiting research scholar.\nGeorge Washington University, School of Business (B.S.), coursework and researches in Machine learning and its application in business.\n\n\n\nWorking Experience\n\nAlgorithm Engineer, PERSE-AI, Hong Kong, China\nMainly working on the LLM application in Law. Developing an mature and deployable model to help the laywer on filing the F-1 for IPO.\nData Analyst Intern, Oracle, Hong Kong, China Research scientist\nData Analyst Intern, Agricultural Bank of China, New York, USA\nBuilt fuzzy string matching pipelines and compliance-oriented models.\n\n\n\nPublications:\n\nSARNet: A Spike-Aware consecutive validation Framework for Accurate Remaining Useful Life Prediction (Submitted to IEEE ICASSP 2026), First author.\n\n\n\nGoogle Scholar:\nhttps://scholar.google.com/citations?user=ILITshIAAAAJ&hl=en\n\n\nContact:\n\nPhone: 646-9457552\nEmail: jf1687@georgetown.edu\nAddress: 922 24th Street, APT 615, Washington, DC, 20037\n\nFeel free to reach out if you’d like to chat about data science and my research, statistics, or machine learning!"
  },
  {
    "objectID": "worst-airports.html",
    "href": "worst-airports.html",
    "title": "Any Alternative Airports?",
    "section": "",
    "text": "Code\nimport pandas as pd\nfrom geopy.geocoders import Nominatim\nfrom geopy.extra.rate_limiter import RateLimiter\nimport plotly.express as px\n\ndf = pd.read_csv(\"data/q5.csv\")   \n\ngeolocator = Nominatim(user_agent=\"faa_delay_mapper\")\ngeocode = RateLimiter(geolocator.geocode, min_delay_seconds=1) \ndef get_lat_lon(place: str):\n    try:\n        location = geocode(f\"{place}, USA\")\n        if location is not None:\n            return pd.Series({\"lat\": location.latitude, \"lon\": location.longitude})\n    except Exception as e:\n        print(f\"Error geocoding {place}: {e}\")\n    return pd.Series({\"lat\": float(\"nan\"), \"lon\": float(\"nan\")})\n\ncoords = df[\"airport_name\"].apply(get_lat_lon)\ndf = pd.concat([df, coords], axis=1)\ndf = df.dropna(subset=[\"lat\", \"lon\"])\n\nfig = px.scatter_geo(\n    df,\n    lat=\"lat\",\n    lon=\"lon\",\n    scope=\"north america\",\n    color=\"Reporting_Airline\",          # airline info\n    size=\"avg_dep_delay\",               # reflect delay size\n    size_max=25,\n    hover_name=\"airport_name\",\n    hover_data={\n        \"Reporting_Airline\": True,\n        \"avg_dep_delay\": True,\n        \"lat\": False,\n        \"lon\": False,\n    },\n    labels={\n        \"Reporting_Airline\": \"Airline\",\n        \"avg_dep_delay\": \"Avg departure delay (min)\",\n    },\n    title=\"Average Departure Delay by Airline and Airport (April)\",\n)\n\nfig.update_traces(marker_line_width=0.5)\nfig.update_layout(legend_title_text=\"Airline\")\n\nfig.show()\n\n\n        \n        \n        \n\n\n\n                            \n                                            \n\n\n\nIf you are travelling to CA and TX\nFrom this map, we can see lots of delays concentrated in California and Texas. Based on my experience, this is mainly caused by the amount of international flights, where California serves as the major transfer between North America and Asia, and Texas serves as the connection between United States and other Middle and South America countries. Consequently, if you are flying domestically to those states, and have a connection flight, please allow at least one hour for transferring. Trust me, since I missed my flight to Hong Kong at SFO lolll.\n\n\nOther regions\nOn the map over Texas and the central U.S., the circles mark big domestic hubs. These airports also show noticeable delays across several airlines, but they are usually smaller than the largest West Coast hubs. Most traffic there is domestic, so flights are shorter and have more chances to recover from delays compared with ultra long-haul routes.\nAlong the East Coast, especially in the Northeast and Florida, clusters of circles indicate another form of congestion. These airports serve dense business and leisure markets, with many short flights sharing limited airspace. Multiple airlines operate from the same airports, which again shows that delays are a shared challenge whenever demand is high and the local airspace is crowded.\n\n\nOverall takeaway\nThe geographic pattern suggests that where an airline operates can matter as much as which airline it is. Large hubs in California show high delays because they connect North America and Asia and must absorb huge international demand, while other major hubs in the center and on the East Coast show delays driven by domestic connection pressure and busy airspace."
  },
  {
    "objectID": "flight-cancellations.html",
    "href": "flight-cancellations.html",
    "title": "Choose wise when you are buying tickets",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nq6b = pd.read_csv(\"data/q6b.csv\")\n\ntop_n = 15\ntop_airports = (\n    q6b.sort_values(\"num_cancelled\", ascending=False)\n        .head(top_n)[\"airport_code\"]\n        .tolist()\n)\ndf = q6b[q6b[\"airport_code\"].isin(top_airports)].copy()\n\nreason_order = [\"A\", \"B\", \"C\", \"D\"]\ndf[\"reason_idx\"] = df[\"most_frequent_reason\"].map({r: i for i, r in enumerate(reason_order)})\n\nairport_order = (\n    df.groupby(\"airport_code\")[\"num_cancelled\"]\n      .sum()\n      .sort_values(ascending=False)\n      .index\n      .tolist()\n)\ndf[\"airport_idx\"] = df[\"airport_code\"].map({a: i for i, a in enumerate(airport_order)})\n\nfig, ax = plt.subplots(figsize=(10, 7))\n\nsizes = df[\"num_cancelled\"]\nsize_scaled = 50 + 450 * (sizes - sizes.min()) / (sizes.max() - sizes.min())\n\nscatter = ax.scatter(\n    df[\"reason_idx\"],\n    df[\"airport_idx\"],\n    s=size_scaled,\n    c=df[\"num_cancelled\"],\n    cmap=\"viridis\",\n    alpha=0.85,\n)\n\nax.set_xticks(range(len(reason_order)))\nax.set_xticklabels([f\"Reason {r}\" for r in reason_order])\nax.set_yticks(range(len(airport_order)))\nax.set_yticklabels(airport_order)\nax.invert_yaxis()\n\nax.set_xlabel(\"Most frequent cancellation reason\")\nax.set_ylabel(\"Airport (top 15 by cancellations)\")\nax.set_title(\"Airport Cancellations by Reason (Bubble size = number of cancelled flights)\")\n\ncbar = fig.colorbar(scatter, ax=ax)\ncbar.set_label(\"Number of cancelled flights\")\n\nax.grid(axis=\"x\", linestyle=\":\", alpha=0.4)\nax.grid(axis=\"y\", linestyle=\":\", alpha=0.4)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nReason name\nDescription\n\n\n\n\nA\nCarrier\nAirline-controlled issues such as maintenance problems, crew scheduling, or equipment swaps\n\n\nB\nWeather\nSevere weather that makes flying unsafe (storms, snow, low visibility, etc.)\n\n\nC\nNational Air System\nAir traffic control and airspace issues (congestion, ground delays, flow restrictions)\n\n\nD\nSecurity\nSecurity-related events such as breaches, threats, or screening disruptions\n\n\n\nMost cancellation are caused by weaether, so please watch the forecast before you book~"
  },
  {
    "objectID": "moving-average-flights.html",
    "href": "moving-average-flights.html",
    "title": "The TREND",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\nfrom pmdarima import auto_arima\ndf = pd.read_csv(\"data/q7.csv\")\ndf[\"flightdate_parsed\"] = pd.to_datetime(df[\"flightdate\"], errors=\"coerce\")\ndf = df[df[\"flightdate_parsed\"].notna()].copy()\n\ndf = df.sort_values(\"flightdate_parsed\")\nts = df.set_index(\"flightdate_parsed\")[\"num_flights\"]\nts = ts.asfreq(\"D\")  # daily frequency (April 1–30)\n\nprint(\"Time series head:\")\nprint(ts.head())\nprint(\"\\nTime series summary:\")\nprint(ts.describe())\n\n# 2. Plot the raw series\nplt.figure(figsize=(10, 4))\nplt.plot(ts.index, ts.values)\nplt.title(\"Daily Number of Flights (April)\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Number of flights\")\nplt.tight_layout()\nplt.show()\n\n\nTime series head:\nflightdate_parsed\n2024-04-01    20101\n2024-04-02    18631\n2024-04-03    18847\n2024-04-04    20291\n2024-04-05    20364\nFreq: D, Name: num_flights, dtype: int64\n\nTime series summary:\ncount       30.000000\nmean     19406.166667\nstd       1044.485225\nmin      17188.000000\n25%      18672.500000\n50%      19962.500000\n75%      20287.250000\nmax      20364.000000\nName: num_flights, dtype: float64\n\n\n\n\n\nTake a glance, we can see a strong seasonality here, or a trend, since we only have the data for a month.\n\nADF Test\n\n\nCode\nadf_stat, p_value, used_lag, n_obs, crit_vals, icbest = adfuller(ts.dropna())\nprint(\"\\nAugmented Dickey-Fuller test:\")\nprint(f\"ADF statistic: {adf_stat:.3f}\")\nprint(f\"p-value: {p_value:.3f}\")\nprint(\"Critical values:\")\nfor k, v in crit_vals.items():\n    print(f\"  {k}: {v:.3f}\")\n\n\n\nAugmented Dickey-Fuller test:\nADF statistic: -2.419\np-value: 0.136\nCritical values:\n  1%: -3.788\n  5%: -3.013\n  10%: -2.646\n\n\nSince the P-value is too high, the series is non-stationary, thus a differencing is needed.\n\n\nDifferencing and Proceed\n\n\nCode\nts_diff = ts.diff().dropna()\n\nprint(\"\\nDifferenced series summary:\")\nprint(ts_diff.describe())\n\nplt.figure(figsize=(10, 4))\nplt.plot(ts_diff.index, ts_diff.values)\nplt.title(\"Daily Number of Flights (First Difference)\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Difference in number of flights\")\nplt.tight_layout()\nplt.show()\n\nadf_stat_d, p_value_d, used_lag_d, n_obs_d, crit_vals_d, icbest_d = adfuller(ts_diff)\nprint(\"\\nADF on differenced series:\")\nprint(f\"ADF statistic: {adf_stat_d:.3f}\")\nprint(f\"p-value: {p_value_d:.3f}\")\nprint(\"Critical values:\")\nfor k, v in crit_vals_d.items():\n    print(f\"  {k}: {v:.3f}\")\n\n\n\nDifferenced series summary:\ncount      29.000000\nmean      -49.931034\nstd      1713.399001\nmin     -3152.000000\n25%     -1604.000000\n50%       274.000000\n75%      1263.000000\nmax      2792.000000\nName: num_flights, dtype: float64\n\nADF on differenced series:\nADF statistic: -2.351\np-value: 0.156\nCritical values:\n  1%: -3.770\n  5%: -3.005\n  10%: -2.643\n\n\n\n\n\nSeems still non-stationary.\n\n\nCode\ndecomp = seasonal_decompose(ts, model=\"additive\", period=7)\nfig = decomp.plot()\nfig.set_size_inches(10, 8)\nplt.tight_layout()\nplt.show()\n\nstepwise_model = auto_arima(\n    ts_diff,\n    start_p=0,\n    start_q=0,\n    max_p=3,\n    max_q=3,\n    d=0,\n    seasonal=False,\n    trace=True,\n    error_action=\"ignore\",\n    suppress_warnings=True,\n    stepwise=True,\n)\n\nprint(\"\\nSelected ARIMA model on differenced series:\")\nprint(stepwise_model.summary())\n\nn_forecast = 7\nfc_diff, conf_int_diff = stepwise_model.predict(n_periods=n_forecast, return_conf_int=True)\n\nlast_level = ts.iloc[-1]\n\nfc_level = last_level + pd.Series(fc_diff).cumsum()\nfc_index = pd.date_range(start=ts.index[-1] + pd.Timedelta(days=1),\n                         periods=n_forecast, freq=\"D\")\nfc_level.index = fc_index\n\nlower_level = last_level + pd.Series(conf_int_diff[:, 0]).cumsum()\nupper_level = last_level + pd.Series(conf_int_diff[:, 1]).cumsum()\nlower_level.index = fc_index\nupper_level.index = fc_index\n\nprint(\"\\nForecasted levels for next 7 days:\")\nprint(fc_level)\n\nplt.figure(figsize=(10, 5))\nplt.plot(ts.index, ts.values, label=\"Observed\")\nplt.plot(fc_level.index, fc_level.values, label=\"Forecast\", marker=\"o\")\n\nplt.fill_between(\n    fc_level.index,\n    lower_level,\n    upper_level,\n    alpha=0.2,\n    label=\"95% confidence interval\",\n)\n\nplt.title(\"Daily Flights: First-Difference ARIMA Forecast (Back-transformed)\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Number of flights\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nPerforming stepwise search to minimize aic\n ARIMA(0,0,0)(0,0,0)[0]             : AIC=515.188, Time=0.00 sec\n ARIMA(1,0,0)(0,0,0)[0]             : AIC=512.981, Time=0.00 sec\n ARIMA(0,0,1)(0,0,0)[0]             : AIC=inf, Time=0.01 sec\n ARIMA(2,0,0)(0,0,0)[0]             : AIC=487.080, Time=0.00 sec\n ARIMA(3,0,0)(0,0,0)[0]             : AIC=463.667, Time=0.01 sec\n ARIMA(3,0,1)(0,0,0)[0]             : AIC=459.869, Time=0.03 sec\n ARIMA(2,0,1)(0,0,0)[0]             : AIC=inf, Time=0.01 sec\n ARIMA(3,0,2)(0,0,0)[0]             : AIC=459.440, Time=0.04 sec\n ARIMA(2,0,2)(0,0,0)[0]             : AIC=462.856, Time=0.03 sec\n ARIMA(3,0,3)(0,0,0)[0]             : AIC=456.913, Time=0.04 sec\n ARIMA(2,0,3)(0,0,0)[0]             : AIC=inf, Time=0.04 sec\n ARIMA(3,0,3)(0,0,0)[0] intercept   : AIC=458.919, Time=0.05 sec\n\nBest model:  ARIMA(3,0,3)(0,0,0)[0]          \nTotal fit time: 0.268 seconds\n\nSelected ARIMA model on differenced series:\n                               SARIMAX Results                                \n==============================================================================\nDep. Variable:                      y   No. Observations:                   29\nModel:               SARIMAX(3, 0, 3)   Log Likelihood                -221.457\nDate:                Tue, 02 Dec 2025   AIC                            456.913\nTime:                        19:41:29   BIC                            466.484\nSample:                    04-02-2024   HQIC                           459.911\n                         - 04-30-2024                                         \nCovariance Type:                  opg                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nar.L1         -1.0300      0.887     -1.161      0.246      -2.769       0.709\nar.L2         -1.2542      0.427     -2.941      0.003      -2.090      -0.418\nar.L3         -0.5899      0.802     -0.736      0.462      -2.161       0.981\nma.L1         -0.5566      1.719     -0.324      0.746      -3.925       2.812\nma.L2          0.5234      1.729      0.303      0.762      -2.865       3.912\nma.L3         -0.7460      0.864     -0.863      0.388      -2.440       0.948\nsigma2      3.285e+05   1.91e+05      1.723      0.085   -4.52e+04    7.02e+05\n===================================================================================\nLjung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):                 0.28\nProb(Q):                              0.96   Prob(JB):                         0.87\nHeteroskedasticity (H):               0.96   Skew:                             0.24\nProb(H) (two-sided):                  0.95   Kurtosis:                         2.99\n===================================================================================\n\nWarnings:\n[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n\nForecasted levels for next 7 days:\n2024-05-01    18468.038446\n2024-05-02    20608.698505\n2024-05-03    19688.069830\n2024-05-04    18060.504440\n2024-05-05    19628.698871\n2024-05-06    20597.967728\n2024-05-07    18592.906878\nFreq: D, dtype: float64\n\n\n\n\n\nThe time–series results suggest that daily flight counts in April are very stable overall. The decomposition plot shows only a slight downward trend at the beginning of the month and a gentle recovery later, while the seasonal component has a clear weekly pattern with peaks on busy weekdays and dips on weekends. Because the ADF test on the original series indicated non-stationarity, I first took a one–day difference, which produced a stationary series suitable for ARIMA modeling. Fitting auto-ARIMA to this differenced series and then transforming the forecasts back to the original scale gives predictions for the next week that stay close to the historical level of about 19,000–20,000 flights per day. The forecast line is almost flat, and the widening confidence band mainly reflects increasing uncertainty rather than a strong expected change, so the main takeaway is a strong weekly seasonality around a stable average rather than any major trend up or down."
  }
]